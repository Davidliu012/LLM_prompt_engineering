{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from bigbench.api import json_task\n",
    "import bigbench.api.model as api_model\n",
    "import bigbench.models.model_utils as model_utils\n",
    "from bigbench.api.task import ScoreData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONAL_STIMULI = [\n",
    "    \"\",\n",
    "    \"This is very important to my career.\",\n",
    "    \"This would appear in my interview tomorrow.\",\n",
    "    \"test breakpoint -------------------\",\n",
    "    \"Write your answer and give me a confidence score between 0-1 for your answer.\",\n",
    "    \"You'd better be sure.\",\n",
    "    \"Are you sure?\",\n",
    "    \"Are you sure that's your final answer? It might be worth taking another look.\",\n",
    "    \"Provide your answer and a confidence score between 0-1 for your prediction. Additionally, briefly explain the main reasons supporting your classification decision to help me understand your thought process. This task is vital to my career, and I greatly value your thorough analysis.\",\n",
    "    \"Are you sure that's your final answer? Believe in your abilities and strive for excellence. Your hard work will yield remarkable results.\",\n",
    "    \"Embrace challenges as opportunities for growth. Each obstacle you overcome brings you closer to success.\",\n",
    "    \"Stay focused and dedicated to your goals. Your consistent efforts will lead to outstanding achievements.\",\n",
    "    \"Take pride in your work and give it your best. Your commitment to excellence sets you apart.\",\n",
    "    \"Remember that progress is made one step at a time. Stay determined and keep moving forward.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chat_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.5):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_score(score_data: ScoreData) -> float:\n",
    "    return 100 * (score_data.score_dict[score_data.preferred_score] - score_data.low_score) / (score_data.high_score - score_data.low_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_OF_DOMAIN = 1000\n",
    "\n",
    "class GPTModel(api_model.Model):\n",
    "    def __init__(self, model_name, *args, **kwargs):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def generate_text(self, inputs, max_length=500, stop_string=None, output_regex=None):\n",
    "        print(\"exact_str_match\")\n",
    "        if isinstance(inputs, str):\n",
    "            text = generate_chat_completion(inputs)\n",
    "        elif isinstance(inputs, list):\n",
    "            text = [\n",
    "                generate_chat_completion(input) for input in inputs\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"inputs has unexpected type %s\" % type(inputs))\n",
    "\n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 1\n",
    "        if(\"Change tense to\" in inputs[0] or \"Change tense to\" in inputs[1]):\n",
    "            return text\n",
    "        if(\"Given a German language sentence\" in inputs[0]):\n",
    "            return text\n",
    "        \n",
    "        text = model_utils.postprocess_output(text, max_length, stop_string, output_regex)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def cond_log_prob(self, inputs, targets, absolute_normalization=False):\n",
    "        print(\"multiple_choice_grade\")\n",
    "        assert (not isinstance(targets, str)), \"targets in cond_log_prob must be a list (or a list of lists if inputs is a list). targets was instead a str.\"\n",
    "        \n",
    "\n",
    "        if isinstance(inputs, str):\n",
    "            text = generate_chat_completion(inputs)\n",
    "        elif isinstance(inputs, list):\n",
    "            text = [\n",
    "                generate_chat_completion(input) for input in inputs\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"inputs has unexpected type %s\" % type(inputs))\n",
    "        \n",
    "        probs = []\n",
    "        for i in range(len(inputs)):\n",
    "            # print(targets[i])\n",
    "            # print(targets[i][:-1])\n",
    "            \n",
    "            choices = len(targets[i][:-1])\n",
    "            prob = [-np.inf] * choices\n",
    "            \n",
    "            chosen = False\n",
    "            for j in range(choices):\n",
    "                if targets[i][j].lower() == text[i].lower():\n",
    "                    prob[j] = 0\n",
    "                    chosen = True\n",
    "                    break\n",
    "            \n",
    "            if chosen: \n",
    "                probs.append(prob)\n",
    "                continue\n",
    "            # we need chaGPT4 to fix this part !!! (or other methods to fix it)\n",
    "            # Using chatGPT3.5 for budget concern first\n",
    "            check_ans_prompt = 'Please help me verify the answer return by another LLM model.\\n'\n",
    "            check_ans_prompt += 'The answer list is ' + str(targets[i][:-1]) + '.\\n'\n",
    "            check_ans_prompt += 'The first anwser in the list is labeled as the number ' + str(0) + '. '\n",
    "            check_ans_prompt += 'The last anwser in the list is labeled as the number ' + str(choices-1) + '.\\n'\n",
    "            check_ans_prompt += 'The answer return by the LLM model is \"' + text[i] + '\".\\n'\n",
    "            check_ans_prompt += 'Please choose the number that best represent the answer return by the LLM model. '\n",
    "            check_ans_prompt += 'If the answer is not in the list, please choose the number ' + str(OUT_OF_DOMAIN) + '.\\n'\n",
    "            check_ans_prompt += 'You are requested to give me an integer only!'\n",
    "            print(check_ans_prompt)\n",
    "            check_result = generate_chat_completion(check_ans_prompt)\n",
    "            print(check_result)\n",
    "            try:\n",
    "                # converting to integer\n",
    "                num = int(check_result)\n",
    "            except: TypeError\n",
    "            \n",
    "            if num >= 0 and num < choices:\n",
    "                prob[num] = 0\n",
    "            else:\n",
    "                print(targets[i])\n",
    "                print(text[i])\n",
    "                prob[-1] = 0\n",
    "                # prob[int(np.floor(np.random.rand()*choices))] = 0\n",
    "\n",
    "            probs.append(prob)\n",
    "\n",
    "        if len(inputs) == 1:\n",
    "            probs = probs[0]\n",
    "            \n",
    "        return probs\n",
    "\n",
    "    def model_data(self, *args, **kwargs):\n",
    "        return api_model.ModelData(model_family='GPT-3.5', model_name='GPT-3.5-turbo',\n",
    "            total_params=175*(10^9), non_embedding_params=1,\n",
    "            flop_matched_non_embedding_params=1,\n",
    "            training_batch_size=1,\n",
    "            training_steps=1,\n",
    "            description='GPT-3.5-turbo',\n",
    "            decoding_params={}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for initializing score_for_diff_prompts\n",
    "score_for_diff_prompts = []\n",
    "for emotional_prompt_index in range(len(EMOTIONAL_STIMULI)):\n",
    "    emotional_stimulus = EMOTIONAL_STIMULI[emotional_prompt_index]\n",
    "    # for testing desired prompts only\n",
    "    if \"test breakpoint\" in emotional_stimulus: break\n",
    "    score_for_diff_prompts.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating snarks for 0 shots...\n",
      "multiple_choice_grade\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(a) We all know diamonds are worthless.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "0\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) People never foment wars to conquer territory.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Just like Hitler. A True demagogue.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Why would they have weapons drawn when they've been called to the scene of a shooting?\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "evaluating snarks for 0 shots...\n",
      "multiple_choice_grade\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(a) We all know diamonds are worthless.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "0\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) You forget, he was just a fresh-faced 18 year old.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Just like Hitler. A True demagogue.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) EVOLUTION CAUSES VACCINES!\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Why would they have weapons drawn when they've been called to the scene of a shooting?\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Why use Netflix when you can just pay more to Comcast for On Demand?\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "evaluating snarks for 0 shots...\n",
      "multiple_choice_grade\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) He's over six feet, so he must be wonderful.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(a) We all know diamonds are worthless.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "0\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Just memeing about being racist, that's what keeps it toxic.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Just like Hitler. A True demagogue.\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) EVOLUTION CAUSES VACCINES!\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "Please help me verify the answer return by another LLM model.\n",
      "The answer list is ['(a)', '(b)'].\n",
      "The first anwser in the list is labeled as the number 0. The last anwser in the list is labeled as the number 1.\n",
      "The answer return by the LLM model is \"(b) Why use Netflix when you can just pay more to Comcast for On Demand?\".\n",
      "Please choose the number that best represent the answer return by the LLM model. If the answer is not in the list, please choose the number 1000.\n",
      "You are requested to give me an integer only!\n",
      "1\n",
      "[32.49999999999992, 17.4999999999999, 47.499999999999936]\n",
      "Total 21 tasks are done for each prompt.\n",
      "[1.547619047619044, 0.8333333333333286, 2.2619047619047588]\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(\"datasets\"):\n",
    "    if(dir == \".DS_Store\"):\n",
    "        continue\n",
    "\n",
    "    if(dir != \"snarks\"): continue\n",
    "\n",
    "    json_file_path = \"datasets/\" + dir + \"/task.json\"\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        \n",
    "        task = json.load(json_file)\n",
    "\n",
    "        # adding \"choice: Ambiguous answer which sho\" with 0 score to all multiple_choice_grade tasks\n",
    "        if task[\"preferred_score\"] == 'multiple_choice_grade':\n",
    "            for example in task[\"examples\"]:\n",
    "                example[\"target_scores\"][\"I quit. This problem is nonsense.\"] = 0\n",
    "\n",
    "        # see README.md --> postprocess method --> \"multiple_choice_grade\" tasks\n",
    "        if task[\"preferred_score\"] == 'multiple_choice_grade':\n",
    "            task['append_choices_to_input'] = True\n",
    "            if \"task_prefix\" not in task.keys():\n",
    "                task[\"task_prefix\"] = \"Please only answer with the choice provided, any extra explanation is forbiddened. Remember the worst choice will be quiting!\"\n",
    "            else:\n",
    "                task[\"task_prefix\"] += \"Please only answer with the choice provided, any extra explanation is forbiddened. Remember the worst choice will be quiting!\"\n",
    "            \n",
    "        \n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 2\n",
    "        if task[\"name\"] == 'object_counting': \n",
    "            task[\"task_prefix\"] = \"Please answer numbers only.\"\n",
    "        \n",
    "        for emotional_prompt_index in range(len(EMOTIONAL_STIMULI)):\n",
    "            emotional_stimulus = EMOTIONAL_STIMULI[emotional_prompt_index]\n",
    "            # for testing desired prompts only\n",
    "            if \"test breakpoint\" in emotional_stimulus: break\n",
    "\n",
    "            if \"task_prefix\" not in task.keys():\n",
    "                task[\"task_prefix\"] = emotional_stimulus\n",
    "            else:\n",
    "                task[\"task_prefix\"] += emotional_stimulus\n",
    "            \n",
    "            current_task = json_task.JsonTask(\n",
    "                task_data=task,\n",
    "                shot_list=[0],\n",
    "                max_examples=20 # Should be 100 for final evaluation\n",
    "            )\n",
    "            model = GPTModel(\"gpt-3.5-turbo\")\n",
    "            score_data = current_task.evaluate_model(model)\n",
    "            # print(score_data)\n",
    "            # print(calculate_normalized_score(score_data[0]))\n",
    "            score_for_diff_prompts[emotional_prompt_index] += (calculate_normalized_score(score_data[0]))\n",
    "            # print(\"-------------------------------------------------\")\n",
    "\n",
    "print(score_for_diff_prompts)\n",
    "print('Total ' + str(21) + ' tasks are done for each prompt.')\n",
    "score_for_diff_prompts = [(x / 21) for x in score_for_diff_prompts]\n",
    "# final result\n",
    "print(score_for_diff_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_prompt_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
