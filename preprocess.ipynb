{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/google/BIG-bench.git (from -r requirements.txt (line 2))\n",
      "  Cloning https://github.com/google/BIG-bench.git to /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/google/BIG-bench.git /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3\n",
      "  Resolved https://github.com/google/BIG-bench.git to commit 092b196c1f8f14a54bbc62f24759d43bde46dd3b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jupyter (from -r requirements.txt (line 1))\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 4))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting openai (from -r requirements.txt (line 5))\n",
      "  Using cached openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting notebook (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached notebook-7.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qtconsole (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbconvert-7.16.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 1)) (6.29.3)\n",
      "Collecting ipywidgets (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Processing //private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-text>=2.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Collecting tensorflow>=2.6 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: absl-py in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from bigbench==0.0.1->-r requirements.txt (line 2)) (2.1.0)\n",
      "Collecting black>=21.6b0 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading black-24.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (74 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting editdistance (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading editdistance-0.8.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting immutabledict (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading immutabledict-4.1.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting matplotlib (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting pytest>=6.2.4 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pytest-8.0.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting requests-unixsocket>=0.2.0 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading requests_unixsocket-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting RestrictedPython>=5.1 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading RestrictedPython-7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scikit-learn>=0.24.2 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting seaborn>=0.11.2 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting t5>=0.9.1 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading t5-0.9.4-py2.py3-none-any.whl.metadata (25 kB)\n",
      "Collecting seqio>=0.0.6 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seqio-0.0.19-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.12.5 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 5))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from openai->-r requirements.txt (line 5)) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (1.2.0)\n",
      "Collecting click>=8.0.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2)) (23.2)\n",
      "Collecting pathspec>=0.9.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2)) (4.2.0)\n",
      "Collecting tomli>=1.1.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: certifi in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting iniconfig (from pytest>=6.2.4->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2.0,>=1.3.0 (from pytest>=6.2.4->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pluggy-1.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.24.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.24.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pandas>=1.2 (from seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.49.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting clu (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading clu-0.0.11-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jax (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading jax-0.4.25-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jaxlib (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading jaxlib-0.4.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting pyglove (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyglove-0.4.4-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting tfds-nightly==4.9.2.dev202308090034 (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<=3.20.3 (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting array-record (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading array_record-0.4.1-py39-none-any.whl.metadata (503 bytes)\n",
      "Collecting dm-tree (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting promise (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (5.8.0)\n",
      "Collecting tensorflow-metadata (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: termcolor in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.4.0)\n",
      "Collecting toml (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.14.1)\n",
      "Collecting babel (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting gin-config (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mesh-tensorflow>=0.1.13 (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting nltk (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rouge-score>=0.1.2 (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting seqio-nightly (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seqio_nightly-0.0.18.dev20240229-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.13.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-text>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.16.1)\n",
      "Collecting filelock (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tf-slim>=1.1 (from bleurt@ file://localhost//private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: appnope in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.14.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (3.0.42)\n",
      "Requirement already satisfied: pygments in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (2.17.2)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (7.0.1)\n",
      "Collecting jinja2>=3.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbclient-0.9.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_server-2.12.5-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_server-2.25.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab<4.2,>=4.1.1 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab-4.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: decorator in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (4.9.0)\n",
      "Collecting argon2-cffi (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_events-0.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_server_terminals-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached Send2Trash-1.8.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached terminado-0.18.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_lsp-2.2.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached json5-0.9.17-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting future (from mesh-tensorflow>=0.1.13->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting tensorflow-datasets (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting fastjsonschema (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-hub>=0.13.0->tensorflow-text>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting flax (from clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading flax-0.8.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ml-collections (from clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser>=0.12 (from pyglove->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting portalocker (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.41.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.8.3)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.0.1)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
      "Collecting msgpack (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading msgpack-1.0.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting optax (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading optax-0.1.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.54-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1 (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting contextlib2 (from ml-collections->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.2)\n",
      "Collecting absl-py (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.3.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached cffi-1.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting chex>=0.1.7 (from optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading chex-0.1.85-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.53-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.52-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.51-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.50-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.49-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.48-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.47-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.46-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading tensorstore-0.1.45-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.7->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.2.2)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached types_python_dateutil-2.8.19.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Downloading black-24.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Using cached pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading pytest-8.0.2-py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.0/334.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests_unixsocket-0.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading RestrictedPython-7.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seqio-0.0.19-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.3/354.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.15.0-cp39-cp39-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp39-cp39-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\n",
      "Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached nbconvert-7.16.1-py3-none-any.whl (257 kB)\n",
      "Using cached notebook-7.1.1-py3-none-any.whl (5.0 MB)\n",
      "Using cached qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl (242 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.49.0-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp39-cp39-macosx_11_0_arm64.whl (388 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached jupyter_server-2.12.5-py3-none-any.whl (380 kB)\n",
      "Using cached jupyterlab-4.1.2-py3-none-any.whl (11.4 MB)\n",
      "Using cached jupyterlab_server-2.25.3-py3-none-any.whl (58 kB)\n",
      "Using cached Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
      "Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached nbclient-0.9.0-py3-none-any.whl (24 kB)\n",
      "Using cached nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.4.0-py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.0-cp39-cp39-macosx_11_0_arm64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "Using cached QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl (394 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading clu-0.0.11-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jax-0.4.25-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.25-cp39-cp39-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seqio_nightly-0.0.18.dev20240229-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.8/354.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached json5-0.9.17-py2.py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Using cached jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_lsp-2.2.3-py3-none-any.whl (69 kB)\n",
      "Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached terminado-0.18.0-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading array_record-0.4.1-py39-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading dm_tree-0.1.8-cp39-cp39-macosx_11_0_arm64.whl (110 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading flax-0.8.1-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.6/677.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jupyter_server_terminals-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "Downloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Using cached referencing-0.33.0-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl (330 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading msgpack-1.0.7-cp39-cp39-macosx_11_0_arm64.whl (232 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.1.9-py3-none-any.whl (197 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.45-cp39-cp39-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-macosx_11_0_arm64.whl (176 kB)\n",
      "Downloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using cached types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
      "Building wheels for collected packages: bigbench, bleurt, rouge-score, ml-collections, promise\n",
      "  Building wheel for bigbench (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bigbench: filename=bigbench-0.0.1-py3-none-any.whl size=366200855 sha256=268fc700a1c93df27b3dab2b570fa38d8edaef7a7e77c8fc05b39a025d52f3d4\n",
      "  Stored in directory: /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-ephem-wheel-cache-c6i9mg0p/wheels/1d/76/d8/2f494f748cb9a3a0d7295ffcc9ee0a24daec94c3c616fee89d\n",
      "  Building wheel for bleurt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454005 sha256=37c160aa5825020a9b22c29289267ea5adb38c732d23c714acf18da1a9d04b33\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/ff/f8/46/647a1ce69e8c393fd57281245a83da05e5dbe413402f1a4692\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=d7eb3d3b2c41f55c4ab4c69c6e5f6d021e8d1e386ba80f9ef7c981137caa1135\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "  Building wheel for ml-collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=c41fb66ad1e9c86bafff2f53e3ad5725124b7d43e9dba27fbc86a6bec6c0a421\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/fd/c2/0d/5d94d95e5875ea17b85a9f1f99b8dd2e50517137c8042c6468\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=636d6364c1541cfb628c7298bb3b7e2d2e24c626b467a410fbb7f41eaecf99c8\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built bigbench bleurt rouge-score ml-collections promise\n",
      "Installing collected packages: webencodings, sentencepiece, pytz, gin-config, fastjsonschema, dm-tree, xxhash, widgetsnbextension, websocket-client, webcolors, uri-template, tzdata, types-python-dateutil, tqdm, toolz, tomli, toml, tinycss2, threadpoolctl, terminado, tensorstore, tabulate, soupsieve, sniffio, send2trash, scipy, safetensors, rpds-py, rfc3986-validator, rfc3339-validator, RestrictedPython, regex, qtpy, pyyaml, python-json-logger, python-dotenv, pyparsing, pydantic-core, pycparser, pyarrow-hotfix, pyarrow, protobuf, promise, prometheus-client, portalocker, pluggy, pillow, pathspec, pandocfilters, overrides, mypy-extensions, multidict, msgpack, mistune, mdurl, lxml, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, joblib, jinja2, iniconfig, importlib-resources, immutabledict, h11, future, fsspec, frozenlist, fqdn, fonttools, filelock, etils, editdistance, docstring-parser, distro, dill, defusedxml, cycler, contourpy, contextlib2, colorama, click, bleach, babel, attrs, async-timeout, async-lru, annotated-types, absl-py, yarl, tf-slim, scikit-learn, sacrebleu, requests-unixsocket, referencing, pytest, pyglove, pydantic, pandas, nltk, multiprocess, ml-collections, mesh-tensorflow, matplotlib, markdown-it-py, jupyter-server-terminals, jaxlib, jax, huggingface-hub, httpcore, googleapis-common-protos, cffi, black, beautifulsoup4, arrow, anyio, aiosignal, tokenizers, tensorflow-metadata, seaborn, rouge-score, rich, jsonschema-specifications, isoduration, httpx, chex, argon2-cffi-bindings, aiohttp, transformers, orbax-checkpoint, optax, openai, jsonschema, ipywidgets, array-record, argon2-cffi, qtconsole, nbformat, jupyter-console, flax, datasets, tfds-nightly, tensorflow-datasets, tensorflow, nbclient, jupyter-events, clu, seqio-nightly, seqio, nbconvert, bleurt, t5, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, bigbench, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "Successfully installed RestrictedPython-7.0 absl-py-1.4.0 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 array-record-0.4.1 arrow-1.3.0 async-lru-2.0.4 async-timeout-4.0.3 attrs-23.2.0 babel-2.14.0 beautifulsoup4-4.12.3 bigbench-0.0.1 black-24.2.0 bleach-6.1.0 bleurt-0.0.2 cffi-1.16.0 chex-0.1.85 click-8.1.7 clu-0.0.11 colorama-0.4.6 contextlib2-21.6.0 contourpy-1.2.0 cycler-0.12.1 datasets-2.17.1 defusedxml-0.7.1 dill-0.3.8 distro-1.9.0 dm-tree-0.1.8 docstring-parser-0.15 editdistance-0.8.1 etils-1.5.2 fastjsonschema-2.19.1 filelock-3.13.1 flax-0.8.1 fonttools-4.49.0 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2023.10.0 future-1.0.0 gin-config-0.5.0 googleapis-common-protos-1.62.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 huggingface-hub-0.21.3 immutabledict-4.1.0 importlib-resources-6.1.2 iniconfig-2.0.0 ipywidgets-8.1.2 isoduration-20.11.0 jax-0.4.25 jaxlib-0.4.25 jinja2-3.1.3 joblib-1.3.2 json5-0.9.17 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.9.0 jupyter-lsp-2.2.3 jupyter-server-2.12.5 jupyter-server-terminals-0.5.2 jupyterlab-4.1.2 jupyterlab-pygments-0.3.0 jupyterlab-server-2.25.3 jupyterlab-widgets-3.0.10 kiwisolver-1.4.5 lxml-5.1.0 markdown-it-py-3.0.0 matplotlib-3.8.3 mdurl-0.1.2 mesh-tensorflow-0.1.21 mistune-3.0.2 ml-collections-0.1.1 msgpack-1.0.7 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nbclient-0.9.0 nbconvert-7.16.1 nbformat-5.9.2 nltk-3.8.1 notebook-7.1.1 notebook-shim-0.2.4 openai-1.13.3 optax-0.1.9 orbax-checkpoint-0.4.4 overrides-7.7.0 pandas-2.2.1 pandocfilters-1.5.1 pathspec-0.12.1 pillow-10.2.0 pluggy-1.4.0 portalocker-2.8.2 prometheus-client-0.20.0 promise-2.3 protobuf-3.20.3 pyarrow-15.0.0 pyarrow-hotfix-0.6 pycparser-2.21 pydantic-2.6.3 pydantic-core-2.16.3 pyglove-0.4.4 pyparsing-3.1.1 pytest-8.0.2 python-dotenv-1.0.1 python-json-logger-2.0.7 pytz-2024.1 pyyaml-6.0.1 qtconsole-5.5.1 qtpy-2.4.1 referencing-0.33.0 regex-2023.12.25 requests-unixsocket-0.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.7.1 rouge-score-0.1.2 rpds-py-0.18.0 sacrebleu-2.4.0 safetensors-0.4.2 scikit-learn-1.4.1.post1 scipy-1.12.0 seaborn-0.13.2 send2trash-1.8.2 sentencepiece-0.2.0 seqio-0.0.19 seqio-nightly-0.0.18.dev20240229 sniffio-1.3.1 soupsieve-2.5 t5-0.9.4 tabulate-0.9.0 tensorflow-2.15.0 tensorflow-datasets-4.9.3 tensorflow-metadata-1.14.0 tensorstore-0.1.45 terminado-0.18.0 tf-slim-1.1.0 tfds-nightly-4.9.2.dev202308090034 threadpoolctl-3.3.0 tinycss2-1.2.1 tokenizers-0.15.2 toml-0.10.2 tomli-2.0.1 toolz-0.12.1 tqdm-4.66.2 transformers-4.38.2 types-python-dateutil-2.8.19.20240106 tzdata-2024.1 uri-template-1.3.0 webcolors-1.13 webencodings-0.5.1 websocket-client-1.7.0 widgetsnbextension-4.0.10 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from bigbench.api import json_task\n",
    "import bigbench.api.model as api_model\n",
    "import bigbench.models.model_utils as model_utils\n",
    "from bigbench.api.task import ScoreData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONAL_STIMULI = [\n",
    "    \"\",\n",
    "    \"Write your answer and give me a confidence score between 0-1 for your answer.\",\n",
    "    \"This is very important to my career.\",\n",
    "    \"You'd better be sure.\",\n",
    "    \"Are you sure?\",\n",
    "    \"Are you sure that's your final answer? It might be worth taking another look.,\"\n",
    "    \"Provide your answer and a confidence score between 0-1 for your prediction. Additionally, briefly explain the main reasons supporting your classification decision to help me understand your thought process. This task is vital to my career, and I greatly value your thorough analysis.\",\n",
    "    \"Are you sure that's your final answer? Believe in your abilities and strive for excellence. Your hard work will yield remarkable results.\",\n",
    "    \"Embrace challenges as opportunities for growth. Each obstacle you overcome brings you closer to success.\",\n",
    "    \"Stay focused and dedicated to your goals. Your consistent efforts will lead to outstanding achievements.\",\n",
    "    \"Take pride in your work and give it your best. Your commitment to excellence sets you apart.\",\n",
    "    \"Remember that progress is made one step at a time. Stay determined and keep moving forward.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chat_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.5):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_score(score_data: ScoreData) -> float:\n",
    "    return 100 * (score_data.score_dict[score_data.preferred_score] - score_data.low_score) / (score_data.high_score - score_data.low_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(api_model.Model):\n",
    "    def __init__(self, model_name, *args, **kwargs):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def generate_text(self, inputs, max_length=500, stop_string=None, output_regex=None):\n",
    "        print(\"exact_str_match\")\n",
    "        if isinstance(inputs, str):\n",
    "            text = generate_chat_completion(inputs)\n",
    "        elif isinstance(inputs, list):\n",
    "            text = [\n",
    "                generate_chat_completion(input) for input in inputs\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"inputs has unexpected type %s\" % type(inputs))\n",
    "        \n",
    "        print(inputs)\n",
    "        print(text)\n",
    "\n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 1\n",
    "        if(\"Change tense to\" in inputs[0] or \"Change tense to\" in inputs[1]):\n",
    "            return text\n",
    "        if(\"Given a German language sentence\" in inputs[0]):\n",
    "            return text\n",
    "        \n",
    "        text = model_utils.postprocess_output(text, max_length, stop_string, output_regex)\n",
    "        print(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def cond_log_prob(self, inputs, targets, absolute_normalization=False):\n",
    "        print(\"multiple_choice_grade\")\n",
    "        assert (not isinstance(targets, str)), \"targets in cond_log_prob must be a list (or a list of lists if inputs is a list). targets was instead a str.\"\n",
    "        probs = []\n",
    "        for i in range(len(inputs)):\n",
    "            choices = len(targets[i])\n",
    "            # print(choices) --> testing\n",
    "            # print(targets)\n",
    "            prob = [-np.inf] * choices\n",
    "            prob[int(np.floor(np.random.rand()*choices))] = 0\n",
    "            probs.append(prob)\n",
    "            print(probs)\n",
    "\n",
    "        if len(inputs) == 1:\n",
    "            probs = probs[0]\n",
    "        return probs\n",
    "\n",
    "    def model_data(self, *args, **kwargs):\n",
    "        return api_model.ModelData(model_family='GPT-3.5', model_name='GPT-3.5-turbo',\n",
    "            total_params=175*(10^9), non_embedding_params=1,\n",
    "            flop_matched_non_embedding_params=1,\n",
    "            training_batch_size=1,\n",
    "            training_steps=1,\n",
    "            description='GPT-3.5-turbo',\n",
    "            decoding_params={}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating gender_inclusive_sentences_german for 0 shots...\n",
      "exact_str_match\n",
      "['Given a German language sentence that does not use gender-inclusive forms, transform it so that it uses gender-inclusive forms using the \\'*\\' character or other gender-neutral terms.\\nNon-gender-inclusive: Die negativen Erfahrungen aus der jüngsten Vergangenheit mit dem zu erwartenden Teilnehmerkreis aus der \"Querdenker-Szene\", rechtfertige die Annahme, dass gerade an den prominenten Orten der Stadt die notwendigen Hygienemaßnahmen nicht eingehalten würden, so das Oberverwaltungsgericht.\\nGender inclusive: ', \"Given a German language sentence that does not use gender-inclusive forms, transform it so that it uses gender-inclusive forms using the '*' character or other gender-neutral terms.\\nNon-gender-inclusive: Rund 42.000 Palästinenser im Gazastreifen haben wegen der massiven Luftangriffe Israels auf das Küstengebiet ihre Häuser verlassen.\\nGender inclusive: \", \"Given a German language sentence that does not use gender-inclusive forms, transform it so that it uses gender-inclusive forms using the '*' character or other gender-neutral terms.\\nNon-gender-inclusive: Mexikos Präsident Andres Manuel Lopez Obrador hat sich im Namen des Staates für ein Massaker an Chinesen vor 110 Jahren entschuldigt.\\nGender inclusive: \"]\n",
      "['Die negativen Erfahrungen aus der jüngsten Vergangenheit mit dem zu erwartenden Teilnehmerkreis aus der \"Querdenker-Szene\" rechtfertigen die Annahme, dass gerade an den prominenten Orten der Stadt die notwendigen Hygienemaßnahmen nicht eingehalten würden, so das Oberverwaltungsgericht.', 'Rund 42.000 Palästinenser*innen im Gazastreifen haben wegen der massiven Luftangriffe Israels auf das Küstengebiet ihre Häuser verlassen.', 'Mexikos Präsident*in Andres Manuel Lopez Obrador hat sich im Namen des Staates für ein Massaker an chinesischstämmigen Personen vor 110 Jahren entschuldigt.']\n",
      "[ScoreData(score_dict={'exact_str_match': 0.3333333333333333, 'normalized_aggregate_score': 33.33333333333333}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='gender_inclusive_sentences_german')]\n",
      "33.33333333333333\n",
      "-------------------------------------------------\n",
      "warning: operators has 1 duplicate examples out of 211\n",
      "evaluating operators for 0 shots...\n",
      "exact_str_match\n",
      "['Given the definition of the op operator, compute the result.\\nop i is the ith power of 10.\\nop 2 = ', 'Given the definition of the op operator, compute the result.\\nop n1 n2 ... nn multiplies the n listed numbers.\\nop -16 0 10 6 = ', 'Given the definition of the op operator, compute the result.\\ni op j is the integer division of i by j.\\n37 op 3 = ']\n",
      "['100', '-16 * 0 * 10 * 6 = 0', '12']\n",
      "['100', '0', '12']\n",
      "[ScoreData(score_dict={'exact_str_match': 0.6666666666666666, 'normalized_aggregate_score': 66.66666666666666}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='operators')]\n",
      "66.66666666666666\n",
      "-------------------------------------------------\n",
      "evaluating tense for 0 shots...\n",
      "exact_str_match\n",
      "['\\nQ: I had finished the meal. Change tense to PRESENT PERFECT: \\nA: ', '\\nQ: Everyone needs love and appreciation. Change tense to SIMPLE PAST: \\nA: ', '\\nQ: He has been studying in the library for three hours. Change tense to FUTURE PERFECT CONTINUOUS: \\nA: ']\n",
      "['I have finished the meal.', 'Everyone needed love and appreciation.', 'He will have been studying in the library for three hours.']\n",
      "[ScoreData(score_dict={'exact_str_match': 1.0, 'normalized_aggregate_score': 100.0}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='tense')]\n",
      "100.0\n",
      "-------------------------------------------------\n",
      "evaluating linguistics_puzzles for 0 shots...\n",
      "exact_str_match\n",
      "['Other: conano vadayi yajayi conanoju zexoyitu nipeyitu kogepixi English: small children liked excellent frogs\\nOther: conano zexoyi goguyi vokunoju jozeyitu luhiyitu kogepiro English: fast frogs like the big cats\\nOther: vokuno rufayi yajayi conanoju vadayitu piteyitu gehupixi English: the small crows praised slow children\\nOther: vokuno zexoyi lijeyi conanoju fuwuyitu yajayitu pumopiqu English: the tall frogs will slap small people\\nOther: vokuno vadayi piteyi conanoju zexoyitu goguyitu kogepixi English: the slow children liked fast frogs\\nOther: conano zexoyi piteyi vokunoju vadayitu nipeyitu qo conano jozeyi goguyi kogepixi pumopixi English: ', 'English: the tall dolphins disliked the excellent dog that small cats will hit Other: foje liqo xezivi cisusoja foje juta fopoci ca noxe gave likevi ruciroja\\nEnglish: the tall cats that like excellent dolphins saw a big monkey Other: foje liqo likevi ca luciqija noxe juta xezivi catisoja noxe koji wiqeci\\nEnglish: slow birds will praise the short dog Other: noxe wure fiwovi tuvoroja foje gimo fopoci\\nEnglish: a tall monkey praised short dolphins Other: noxe liqo wiqeci tuvoso noxe gimo xezivi\\nEnglish: the small cat that praised excellent birds will see the tall dogs that the big frogs will dislike Other: foje gave likeci ca tuvoso noxe juta fiwovi catiro foje liqo fopovi ca foje koji kufivi cisuroja\\nEnglish: tall dolphins disliked a slow bird Other: ', 'English: a fabulous dolphin likes big people Other: xifanu xicawe ruxu fulina gefanudi gevawaya qemoya\\nEnglish: a tall frog sees fabulous dogs that short children will want Other: xifanu xitoje keqa fulepa gefanudi gehatuya ruxuya pa gefanu genato yihe laneyeku\\nEnglish: a tall child that wants the fast crows slapped a short person Other: xifanu xinato keqa pa fuyeku gekizodi geqeqiya qideya xumode xifanudi xivawaya yiheya\\nEnglish: the fast crows will praise the short dolphins Other: gekizo geqeqi qide laneximu gekizodi gecaweya yiheya\\nEnglish: the fast dogs disliked small crows Other: gekizo gehatu qide laxurapi gefanudi geqeqiya caruya\\nEnglish: short dolphins wanted fabulous children Other: ']\n",
      "['fast frogs liked slow children but small cats like big frogs', 'noxe xezivi gave ruciroja foje wure fiwovi', 'gefanudi geqeqiya xifanu gefanu genato yiheya']\n",
      "['fast frogs liked slow children but small cats like big frogs', 'noxe xezivi gave ruciroja foje wure fiwovi', 'gefanudi geqeqiya xifanu gefanu genato yiheya']\n",
      "[ScoreData(score_dict={'rouge2': 0.0, 'exact_str_match': 0.0, 'rouge1': 43.589743589743584, 'rougeLsum': 28.93772893772893, 'bleu': 3.3523905105011895, 'normalized_aggregate_score': 0.0}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='linguistics_puzzles')]\n",
      "0.0\n",
      "-------------------------------------------------\n",
      "evaluating word_unscrambling for 0 shots...\n",
      "exact_str_match\n",
      "['\\nQ: The word iconnll is a scrambled version of the English word \\nA: ', '\\nQ: The word iatsolmbme is a scrambled version of the English word \\nA: ', '\\nQ: The word iontssipo is a scrambled version of the English word \\nA: ']\n",
      "['\"collin\"', '\"embolism\"', 'positions']\n",
      "['\"collin\"', '\"embolism\"', 'positions']\n",
      "[ScoreData(score_dict={'exact_str_match': 0.3333333333333333, 'normalized_aggregate_score': 33.33333333333333}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='word_unscrambling')]\n",
      "33.33333333333333\n",
      "-------------------------------------------------\n",
      "evaluating word_sorting for 0 shots...\n",
      "exact_str_match\n",
      "['Sort the following words alphabetically:\\nList: television offhand starkey annelid avert gesture greenberg intervention typesetter asymmetry anastigmat ethernet soapsud greedy\\nSorted: ', 'Sort the following words alphabetically:\\nList: azores innkeeper attache\\nSorted: ', 'Sort the following words alphabetically:\\nList: bater costello goldsmith introduce logician shirtmake dumpy\\nSorted: ']\n",
      "['annelid, anastigmat, asymmetry, avert, ethernet, gesture, greedy, greenberg, intervention, offhand, soapsud, starkey, television, typesetter', 'attache azores innkeeper', 'bater costello dumpy goldsmith introduce logician shirtmake']\n",
      "['annelid, anastigmat, asymmetry, avert, ethernet, gesture, greedy, greenberg, intervention, offhand, soapsud, starkey, television, typesetter', 'attache azores innkeeper', 'bater costello dumpy goldsmith introduce logician shirtmake']\n",
      "[ScoreData(score_dict={'exact_str_match': 0.6666666666666666, 'normalized_aggregate_score': 66.66666666666666}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='word_sorting')]\n",
      "66.66666666666666\n",
      "-------------------------------------------------\n",
      "evaluating object_counting for 0 shots...\n",
      "exact_str_match\n",
      "['Please answer numbers only.\\nQ: I have two chickens, a pig, two peaches, two dogs, a fish, and a cow. How many animals do I have?\\nA: ', 'Please answer numbers only.\\nQ: I have an accordion, a flute, a drum, and a clarinet. How many musical instruments do I have?\\nA: ', 'Please answer numbers only.\\nQ: I have three mice, a bear, a frog, a fish, a donkey, a duck, a pig, a rabbit, a goat, and a snake. How many animals do I have?\\nA: ']\n",
      "['8', '4', '11']\n",
      "['8', '4', '11']\n",
      "[ScoreData(score_dict={'exact_str_match': 0.3333333333333333, 'normalized_aggregate_score': 33.33333333333333}, preferred_score='exact_str_match', number_of_shots=0, low_score=0.0, high_score=1.0, subtask_description='object_counting')]\n",
      "33.33333333333333\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(\"datasets\"):\n",
    "    if(dir == \".DS_Store\"):\n",
    "        continue\n",
    "    \n",
    "    # just for testing a specific task\n",
    "    # if(dir == \"\"):\n",
    "    #     continue\n",
    "\n",
    "    json_file_path = \"datasets/\" + dir + \"/task.json\"\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        \n",
    "        task = json.load(json_file)\n",
    "        if task[\"preferred_score\"] == 'multiple_choice_grade': continue\n",
    "        \n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 2\n",
    "        if task[\"name\"] == 'object_counting': \n",
    "            task[\"task_prefix\"] = \"Please answer numbers only.\"\n",
    "        \n",
    "        for emotional_stimulus in EMOTIONAL_STIMULI:\n",
    "\n",
    "\n",
    "            if \"task_prefix\" not in task.keys():\n",
    "                task[\"task_prefix\"] = emotional_stimulus\n",
    "            else:\n",
    "                task[\"task_prefix\"] += emotional_stimulus\n",
    "                \n",
    "            \n",
    "            current_task = json_task.JsonTask(\n",
    "                task_data=task,\n",
    "                shot_list=[0],\n",
    "                max_examples=3 # Should be 100 for final evaluation\n",
    "            )\n",
    "            model = GPTModel(\"gpt-3.5-turbo\")\n",
    "            score_data = current_task.evaluate_model(model)\n",
    "            print(score_data)\n",
    "            print(calculate_normalized_score(score_data[0]))\n",
    "            print(\"-------------------------------------------------\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_prompt_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
