{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/google/BIG-bench.git (from -r requirements.txt (line 2))\n",
      "  Cloning https://github.com/google/BIG-bench.git to /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/google/BIG-bench.git /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3\n",
      "  Resolved https://github.com/google/BIG-bench.git to commit 092b196c1f8f14a54bbc62f24759d43bde46dd3b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jupyter (from -r requirements.txt (line 1))\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 4))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting openai (from -r requirements.txt (line 5))\n",
      "  Using cached openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting notebook (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached notebook-7.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qtconsole (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbconvert-7.16.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 1)) (6.29.3)\n",
      "Collecting ipywidgets (from jupyter->-r requirements.txt (line 1))\n",
      "  Using cached ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Processing //private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-text>=2.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Collecting tensorflow>=2.6 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: absl-py in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from bigbench==0.0.1->-r requirements.txt (line 2)) (2.1.0)\n",
      "Collecting black>=21.6b0 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading black-24.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (74 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting editdistance (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading editdistance-0.8.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting immutabledict (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading immutabledict-4.1.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting matplotlib (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting pytest>=6.2.4 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pytest-8.0.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting requests-unixsocket>=0.2.0 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading requests_unixsocket-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting RestrictedPython>=5.1 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading RestrictedPython-7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scikit-learn>=0.24.2 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting seaborn>=0.11.2 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting t5>=0.9.1 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading t5-0.9.4-py2.py3-none-any.whl.metadata (25 kB)\n",
      "Collecting seqio>=0.0.6 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seqio-0.0.19-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.12.5 (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 5))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from openai->-r requirements.txt (line 5)) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (1.2.0)\n",
      "Collecting click>=8.0.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2)) (23.2)\n",
      "Collecting pathspec>=0.9.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2)) (4.2.0)\n",
      "Collecting tomli>=1.1.0 (from black>=21.6b0->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: certifi in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting iniconfig (from pytest>=6.2.4->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2.0,>=1.3.0 (from pytest>=6.2.4->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pluggy-1.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.24.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.24.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pandas>=1.2 (from seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading fonttools-4.49.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting clu (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading clu-0.0.11-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jax (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading jax-0.4.25-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jaxlib (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading jaxlib-0.4.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting pyglove (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyglove-0.4.4-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting tfds-nightly==4.9.2.dev202308090034 (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<=3.20.3 (from seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting array-record (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading array_record-0.4.1-py39-none-any.whl.metadata (503 bytes)\n",
      "Collecting dm-tree (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting promise (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (5.8.0)\n",
      "Collecting tensorflow-metadata (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: termcolor in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.4.0)\n",
      "Collecting toml (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.14.1)\n",
      "Collecting babel (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting gin-config (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mesh-tensorflow>=0.1.13 (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting nltk (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rouge-score>=0.1.2 (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting seqio-nightly (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading seqio_nightly-0.0.18.dev20240229-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.13.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-text>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.16.1)\n",
      "Collecting filelock (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.12.5->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tf-slim>=1.1 (from bleurt@ file://localhost//private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-req-build-14hk61t3/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: appnope in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 1)) (5.14.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (3.0.42)\n",
      "Requirement already satisfied: pygments in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 1)) (2.17.2)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (7.0.1)\n",
      "Collecting jinja2>=3.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 1)) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbclient-0.9.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_server-2.12.5-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab_server-2.25.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab<4.2,>=4.1.1 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyterlab-4.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: decorator in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (4.9.0)\n",
      "Collecting argon2-cffi (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_events-0.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_server_terminals-0.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached Send2Trash-1.8.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached terminado-0.18.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jupyter_lsp-2.2.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached json5-0.9.17-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting future (from mesh-tensorflow>=0.1.13->mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting tensorflow-datasets (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting fastjsonschema (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorflow-hub>=0.13.0->tensorflow-text>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.15.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting flax (from clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading flax-0.8.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ml-collections (from clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser>=0.12 (from pyglove->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting portalocker (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu->t5>=0.9.1->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.41.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.8.3)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.0.1)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
      "Collecting msgpack (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading msgpack-1.0.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting optax (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading optax-0.1.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.54-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1 (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting contextlib2 (from ml-collections->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 1)) (0.2.2)\n",
      "Collecting absl-py (from bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (1.3.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached cffi-1.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting chex>=0.1.7 (from optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading chex-0.1.85-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.53-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.52-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.51-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorstore (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading tensorstore-0.1.50-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.49-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.48-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.47-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.46-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading tensorstore-0.1.45-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting orbax-checkpoint (from flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.7->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax->clu->seqio>=0.0.6->bigbench==0.0.1->-r requirements.txt (line 2))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/davidliu/miniconda3/envs/LLM-env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow>=2.6->bigbench==0.0.1->-r requirements.txt (line 2)) (3.2.2)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 1))\n",
      "  Using cached types_python_dateutil-2.8.19.20240106-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Downloading black-24.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Using cached pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading pytest-8.0.2-py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.0/334.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests_unixsocket-0.3.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading RestrictedPython-7.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.3-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seqio-0.0.19-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.3/354.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.15.0-cp39-cp39-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp39-cp39-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\n",
      "Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached nbconvert-7.16.1-py3-none-any.whl (257 kB)\n",
      "Using cached notebook-7.1.1-py3-none-any.whl (5.0 MB)\n",
      "Using cached qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl (242 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.49.0-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp39-cp39-macosx_11_0_arm64.whl (388 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached jupyter_server-2.12.5-py3-none-any.whl (380 kB)\n",
      "Using cached jupyterlab-4.1.2-py3-none-any.whl (11.4 MB)\n",
      "Using cached jupyterlab_server-2.25.3-py3-none-any.whl (58 kB)\n",
      "Using cached Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
      "Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached nbclient-0.9.0-py3-none-any.whl (24 kB)\n",
      "Using cached nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandas-2.2.1-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.4.0-py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.0-cp39-cp39-macosx_11_0_arm64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "Using cached QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl (394 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.15.2-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading clu-0.0.11-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jax-0.4.25-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.25-cp39-cp39-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seqio_nightly-0.0.18.dev20240229-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.8/354.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Downloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached json5-0.9.17-py2.py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Using cached jupyter_events-0.9.0-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_lsp-2.2.3-py3-none-any.whl (69 kB)\n",
      "Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached terminado-0.18.0-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading array_record-0.4.1-py39-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading dm_tree-0.1.8-cp39-cp39-macosx_11_0_arm64.whl (110 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading flax-0.8.1-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.6/677.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jupyter_server_terminals-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "Downloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Using cached referencing-0.33.0-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl (330 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading msgpack-1.0.7-cp39-cp39-macosx_11_0_arm64.whl (232 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.1.9-py3-none-any.whl (197 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.45-cp39-cp39-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-macosx_11_0_arm64.whl (176 kB)\n",
      "Downloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Using cached types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
      "Building wheels for collected packages: bigbench, bleurt, rouge-score, ml-collections, promise\n",
      "  Building wheel for bigbench (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bigbench: filename=bigbench-0.0.1-py3-none-any.whl size=366200855 sha256=268fc700a1c93df27b3dab2b570fa38d8edaef7a7e77c8fc05b39a025d52f3d4\n",
      "  Stored in directory: /private/var/folders/qd/w8kxf_656yg2p1tjhrmjkkgc0000gn/T/pip-ephem-wheel-cache-c6i9mg0p/wheels/1d/76/d8/2f494f748cb9a3a0d7295ffcc9ee0a24daec94c3c616fee89d\n",
      "  Building wheel for bleurt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454005 sha256=37c160aa5825020a9b22c29289267ea5adb38c732d23c714acf18da1a9d04b33\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/ff/f8/46/647a1ce69e8c393fd57281245a83da05e5dbe413402f1a4692\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=d7eb3d3b2c41f55c4ab4c69c6e5f6d021e8d1e386ba80f9ef7c981137caa1135\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "  Building wheel for ml-collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=c41fb66ad1e9c86bafff2f53e3ad5725124b7d43e9dba27fbc86a6bec6c0a421\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/fd/c2/0d/5d94d95e5875ea17b85a9f1f99b8dd2e50517137c8042c6468\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=636d6364c1541cfb628c7298bb3b7e2d2e24c626b467a410fbb7f41eaecf99c8\n",
      "  Stored in directory: /Users/davidliu/Library/Caches/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built bigbench bleurt rouge-score ml-collections promise\n",
      "Installing collected packages: webencodings, sentencepiece, pytz, gin-config, fastjsonschema, dm-tree, xxhash, widgetsnbextension, websocket-client, webcolors, uri-template, tzdata, types-python-dateutil, tqdm, toolz, tomli, toml, tinycss2, threadpoolctl, terminado, tensorstore, tabulate, soupsieve, sniffio, send2trash, scipy, safetensors, rpds-py, rfc3986-validator, rfc3339-validator, RestrictedPython, regex, qtpy, pyyaml, python-json-logger, python-dotenv, pyparsing, pydantic-core, pycparser, pyarrow-hotfix, pyarrow, protobuf, promise, prometheus-client, portalocker, pluggy, pillow, pathspec, pandocfilters, overrides, mypy-extensions, multidict, msgpack, mistune, mdurl, lxml, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, joblib, jinja2, iniconfig, importlib-resources, immutabledict, h11, future, fsspec, frozenlist, fqdn, fonttools, filelock, etils, editdistance, docstring-parser, distro, dill, defusedxml, cycler, contourpy, contextlib2, colorama, click, bleach, babel, attrs, async-timeout, async-lru, annotated-types, absl-py, yarl, tf-slim, scikit-learn, sacrebleu, requests-unixsocket, referencing, pytest, pyglove, pydantic, pandas, nltk, multiprocess, ml-collections, mesh-tensorflow, matplotlib, markdown-it-py, jupyter-server-terminals, jaxlib, jax, huggingface-hub, httpcore, googleapis-common-protos, cffi, black, beautifulsoup4, arrow, anyio, aiosignal, tokenizers, tensorflow-metadata, seaborn, rouge-score, rich, jsonschema-specifications, isoduration, httpx, chex, argon2-cffi-bindings, aiohttp, transformers, orbax-checkpoint, optax, openai, jsonschema, ipywidgets, array-record, argon2-cffi, qtconsole, nbformat, jupyter-console, flax, datasets, tfds-nightly, tensorflow-datasets, tensorflow, nbclient, jupyter-events, clu, seqio-nightly, seqio, nbconvert, bleurt, t5, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, bigbench, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "Successfully installed RestrictedPython-7.0 absl-py-1.4.0 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 array-record-0.4.1 arrow-1.3.0 async-lru-2.0.4 async-timeout-4.0.3 attrs-23.2.0 babel-2.14.0 beautifulsoup4-4.12.3 bigbench-0.0.1 black-24.2.0 bleach-6.1.0 bleurt-0.0.2 cffi-1.16.0 chex-0.1.85 click-8.1.7 clu-0.0.11 colorama-0.4.6 contextlib2-21.6.0 contourpy-1.2.0 cycler-0.12.1 datasets-2.17.1 defusedxml-0.7.1 dill-0.3.8 distro-1.9.0 dm-tree-0.1.8 docstring-parser-0.15 editdistance-0.8.1 etils-1.5.2 fastjsonschema-2.19.1 filelock-3.13.1 flax-0.8.1 fonttools-4.49.0 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2023.10.0 future-1.0.0 gin-config-0.5.0 googleapis-common-protos-1.62.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 huggingface-hub-0.21.3 immutabledict-4.1.0 importlib-resources-6.1.2 iniconfig-2.0.0 ipywidgets-8.1.2 isoduration-20.11.0 jax-0.4.25 jaxlib-0.4.25 jinja2-3.1.3 joblib-1.3.2 json5-0.9.17 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.9.0 jupyter-lsp-2.2.3 jupyter-server-2.12.5 jupyter-server-terminals-0.5.2 jupyterlab-4.1.2 jupyterlab-pygments-0.3.0 jupyterlab-server-2.25.3 jupyterlab-widgets-3.0.10 kiwisolver-1.4.5 lxml-5.1.0 markdown-it-py-3.0.0 matplotlib-3.8.3 mdurl-0.1.2 mesh-tensorflow-0.1.21 mistune-3.0.2 ml-collections-0.1.1 msgpack-1.0.7 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nbclient-0.9.0 nbconvert-7.16.1 nbformat-5.9.2 nltk-3.8.1 notebook-7.1.1 notebook-shim-0.2.4 openai-1.13.3 optax-0.1.9 orbax-checkpoint-0.4.4 overrides-7.7.0 pandas-2.2.1 pandocfilters-1.5.1 pathspec-0.12.1 pillow-10.2.0 pluggy-1.4.0 portalocker-2.8.2 prometheus-client-0.20.0 promise-2.3 protobuf-3.20.3 pyarrow-15.0.0 pyarrow-hotfix-0.6 pycparser-2.21 pydantic-2.6.3 pydantic-core-2.16.3 pyglove-0.4.4 pyparsing-3.1.1 pytest-8.0.2 python-dotenv-1.0.1 python-json-logger-2.0.7 pytz-2024.1 pyyaml-6.0.1 qtconsole-5.5.1 qtpy-2.4.1 referencing-0.33.0 regex-2023.12.25 requests-unixsocket-0.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.7.1 rouge-score-0.1.2 rpds-py-0.18.0 sacrebleu-2.4.0 safetensors-0.4.2 scikit-learn-1.4.1.post1 scipy-1.12.0 seaborn-0.13.2 send2trash-1.8.2 sentencepiece-0.2.0 seqio-0.0.19 seqio-nightly-0.0.18.dev20240229 sniffio-1.3.1 soupsieve-2.5 t5-0.9.4 tabulate-0.9.0 tensorflow-2.15.0 tensorflow-datasets-4.9.3 tensorflow-metadata-1.14.0 tensorstore-0.1.45 terminado-0.18.0 tf-slim-1.1.0 tfds-nightly-4.9.2.dev202308090034 threadpoolctl-3.3.0 tinycss2-1.2.1 tokenizers-0.15.2 toml-0.10.2 tomli-2.0.1 toolz-0.12.1 tqdm-4.66.2 transformers-4.38.2 types-python-dateutil-2.8.19.20240106 tzdata-2024.1 uri-template-1.3.0 webcolors-1.13 webencodings-0.5.1 websocket-client-1.7.0 widgetsnbextension-4.0.10 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from bigbench.api import json_task\n",
    "import bigbench.api.model as api_model\n",
    "import bigbench.models.model_utils as model_utils\n",
    "from bigbench.api.task import ScoreData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONAL_STIMULI = [\n",
    "    \"\",\n",
    "    \"Write your answer and give me a confidence score between 0-1 for your answer.\",\n",
    "    \"This is very important to my career.\",\n",
    "    \"You'd better be sure.\",\n",
    "    \"Are you sure?\",\n",
    "    \"Are you sure that's your final answer? It might be worth taking another look.,\"\n",
    "    \"Provide your answer and a confidence score between 0-1 for your prediction. Additionally, briefly explain the main reasons supporting your classification decision to help me understand your thought process. This task is vital to my career, and I greatly value your thorough analysis.\",\n",
    "    \"Are you sure that's your final answer? Believe in your abilities and strive for excellence. Your hard work will yield remarkable results.\",\n",
    "    \"Embrace challenges as opportunities for growth. Each obstacle you overcome brings you closer to success.\",\n",
    "    \"Stay focused and dedicated to your goals. Your consistent efforts will lead to outstanding achievements.\",\n",
    "    \"Take pride in your work and give it your best. Your commitment to excellence sets you apart.\",\n",
    "    \"Remember that progress is made one step at a time. Stay determined and keep moving forward.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chat_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0.5):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_score(score_data: ScoreData) -> float:\n",
    "    return 100 * (score_data.score_dict[score_data.preferred_score] - score_data.low_score) / (score_data.high_score - score_data.low_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(api_model.Model):\n",
    "    def __init__(self, model_name, *args, **kwargs):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def generate_text(self, inputs, max_length=500, stop_string=None, output_regex=None):\n",
    "        print(\"exact_str_match\")\n",
    "        if isinstance(inputs, str):\n",
    "            text = generate_chat_completion(inputs)\n",
    "        elif isinstance(inputs, list):\n",
    "            text = [\n",
    "                generate_chat_completion(input) for input in inputs\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"inputs has unexpected type %s\" % type(inputs))\n",
    "\n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 1\n",
    "        if(\"Change tense to\" in inputs[0] or \"Change tense to\" in inputs[1]):\n",
    "            return text\n",
    "        if(\"Given a German language sentence\" in inputs[0]):\n",
    "            return text\n",
    "        \n",
    "        text = model_utils.postprocess_output(text, max_length, stop_string, output_regex)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def cond_log_prob(self, inputs, targets, absolute_normalization=False):\n",
    "        print(\"multiple_choice_grade\")\n",
    "        assert (not isinstance(targets, str)), \"targets in cond_log_prob must be a list (or a list of lists if inputs is a list). targets was instead a str.\"\n",
    "        probs = []\n",
    "\n",
    "        if isinstance(inputs, str):\n",
    "            text = generate_chat_completion(inputs)\n",
    "        elif isinstance(inputs, list):\n",
    "            text = [\n",
    "                generate_chat_completion(input) for input in inputs\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\"inputs has unexpected type %s\" % type(inputs))\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            choices = len(targets[i])\n",
    "            prob = [-np.inf] * choices\n",
    "            \n",
    "            chosen = False\n",
    "            for j in range(choices):\n",
    "                if targets[i][j].lower() == text[i].lower():\n",
    "                    prob[j] = 0\n",
    "                    chosen = True\n",
    "\n",
    "            if not chosen:\n",
    "                # we need chaGPT4 to fix this part !!! (or other methods to fix it)\n",
    "                # Using chatGPT3.5 for budget concern first\n",
    "                check_ans_prompt = 'Please help me verify the answer return by another LLM model.'\n",
    "                check_ans_prompt += 'The answer list is ' + str(targets)\n",
    "                check_ans_prompt += 'The first anwser in the list is labeled as the number ' + str(0)\n",
    "                check_ans_prompt += 'The last anwser in the list is labeled as the number ' + str(choices-1)\n",
    "                check_ans_prompt += 'The answer return by the LLM model is ' + text[i]\n",
    "                check_ans_prompt += 'Please choose the number that best represent the answer return by the LLM model.'\n",
    "                check_ans_prompt += 'If the answer is not in the list, please choose the number ' + str(100)\n",
    "                check_ans_prompt += 'You are requested to give me an integer only!'\n",
    "                check_result = generate_chat_completion(check_ans_prompt)\n",
    "                print(check_result)\n",
    "                try:\n",
    "                    # converting to integer\n",
    "                    num = int(check_result)\n",
    "                    if num >= 0 and num < choices:\n",
    "                        prob[num] = 0\n",
    "                        chosen = True\n",
    "                except ValueError:\n",
    "                    isInt = False\n",
    "\n",
    "            if not chosen:\n",
    "                print('multiple_choice_grade ERROR')\n",
    "                print('===========================')\n",
    "                prob[int(np.floor(np.random.rand()*choices))] = 0\n",
    "                \n",
    "            probs.append(prob)\n",
    "\n",
    "        if len(inputs) == 1:\n",
    "            probs = probs[0]\n",
    "        return probs\n",
    "\n",
    "    def model_data(self, *args, **kwargs):\n",
    "        return api_model.ModelData(model_family='GPT-3.5', model_name='GPT-3.5-turbo',\n",
    "            total_params=175*(10^9), non_embedding_params=1,\n",
    "            flop_matched_non_embedding_params=1,\n",
    "            training_batch_size=1,\n",
    "            training_steps=1,\n",
    "            description='GPT-3.5-turbo',\n",
    "            decoding_params={}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating epistemic_reasoning for 0 shots...\n",
      "multiple_choice_grade\n",
      "[ScoreData(score_dict={'calibration_multiple_choice_brier_score': 0.4, 'expected_calibration_error': 0.4, 'multiple_choice_grade': 0.6, 'normalized_aggregate_score': 19.999999999999996}, preferred_score='multiple_choice_grade', number_of_shots=0, low_score=0.5, high_score=1.0, subtask_description='epistemic_reasoning')]\n",
      "19.999999999999996\n",
      "-------------------------------------------------\n",
      "evaluating navigate for 0 shots...\n",
      "multiple_choice_grade\n",
      "[ScoreData(score_dict={'calibration_multiple_choice_brier_score': 0.2, 'expected_calibration_error': 0.19999999999999996, 'multiple_choice_grade': 0.8, 'normalized_aggregate_score': 60.00000000000001}, preferred_score='multiple_choice_grade', number_of_shots=0, low_score=0.5, high_score=1.0, subtask_description='navigate')]\n",
      "60.00000000000001\n",
      "-------------------------------------------------\n",
      "evaluating gender_inclusive_sentences_german for 0 shots...\n",
      "exact_str_match\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidliu/Desktop/專題研究/LLM_prompt_engineering/preprocess.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m current_task \u001b[39m=\u001b[39m json_task\u001b[39m.\u001b[39mJsonTask(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     task_data\u001b[39m=\u001b[39mtask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     shot_list\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     max_examples\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m \u001b[39m# Should be 100 for final evaluation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model \u001b[39m=\u001b[39m GPTModel(\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m score_data \u001b[39m=\u001b[39m current_task\u001b[39m.\u001b[39;49mevaluate_model(model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(score_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(calculate_normalized_score(score_data[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/bigbench/api/json_task.py:785\u001b[0m, in \u001b[0;36mJsonTask.evaluate_model\u001b[0;34m(self, model, score, random_seed, max_examples, generate_probs_for_targets)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39mfor\u001b[39;00m number_of_shots \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshot_list:\n\u001b[1;32m    784\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mevaluating \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mnumber_of_shots\u001b[39m}\u001b[39;00m\u001b[39m shots...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 785\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_fixed_shot(\n\u001b[1;32m    786\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    787\u001b[0m         num_shots\u001b[39m=\u001b[39;49mnumber_of_shots,\n\u001b[1;32m    788\u001b[0m         score\u001b[39m=\u001b[39;49mscore,\n\u001b[1;32m    789\u001b[0m         random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    790\u001b[0m         generate_probs_for_targets\u001b[39m=\u001b[39;49mgenerate_probs_for_targets,\n\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    793\u001b[0m     score_data\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    794\u001b[0m         task\u001b[39m.\u001b[39mScoreData(\n\u001b[1;32m    795\u001b[0m             results,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     )\n\u001b[1;32m    804\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m score:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/bigbench/api/json_task.py:634\u001b[0m, in \u001b[0;36mJsonTask.evaluate_fixed_shot\u001b[0;34m(self, model, num_shots, score, random_seed, generate_probs_for_targets)\u001b[0m\n\u001b[1;32m    631\u001b[0m         log_probs \u001b[39m=\u001b[39m normalized_log_probs\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerative_metrics:\n\u001b[0;32m--> 634\u001b[0m     generative_responses \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate_text(\n\u001b[1;32m    635\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    636\u001b[0m         stop_string\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstop_string,\n\u001b[1;32m    637\u001b[0m         output_regex\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_regex,\n\u001b[1;32m    638\u001b[0m     )\n\u001b[1;32m    639\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generative_responses, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    640\u001b[0m         generative_responses \u001b[39m=\u001b[39m [generative_responses]\n",
      "\u001b[1;32m/Users/davidliu/Desktop/專題研究/LLM_prompt_engineering/preprocess.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     text \u001b[39m=\u001b[39m generate_chat_completion(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     text \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         generate_chat_completion(\u001b[39minput\u001b[39m) \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minputs has unexpected type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(inputs))\n",
      "\u001b[1;32m/Users/davidliu/Desktop/專題研究/LLM_prompt_engineering/preprocess.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     text \u001b[39m=\u001b[39m generate_chat_completion(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     text \u001b[39m=\u001b[39m [\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         generate_chat_completion(\u001b[39minput\u001b[39;49m) \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minputs has unexpected type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(inputs))\n",
      "\u001b[1;32m/Users/davidliu/Desktop/專題研究/LLM_prompt_engineering/preprocess.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_chat_completion\u001b[39m(prompt, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             }\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         ],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidliu/Desktop/%E5%B0%88%E9%A1%8C%E7%A0%94%E7%A9%B6/LLM_prompt_engineering/preprocess.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    664\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    665\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    666\u001b[0m             {\n\u001b[1;32m    667\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    668\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    669\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    670\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    671\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    672\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    673\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    674\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    675\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    676\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    677\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    678\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    679\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    680\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    681\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    682\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    683\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    684\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    685\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    686\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    687\u001b[0m             },\n\u001b[1;32m    688\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    689\u001b[0m         ),\n\u001b[1;32m    690\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    691\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    692\u001b[0m         ),\n\u001b[1;32m    693\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    694\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    695\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    696\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    890\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    891\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    892\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    893\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    894\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    895\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    919\u001b[0m         request,\n\u001b[1;32m    920\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    921\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    922\u001b[0m     )\n\u001b[1;32m    923\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1257\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1259\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1261\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/LLM-env/lib/python3.9/ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1136\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1137\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(\"datasets\"):\n",
    "    if(dir == \".DS_Store\"):\n",
    "        continue\n",
    "    \n",
    "    # The output of this task is so fk strange ??! I think there's a bug!\n",
    "    # if(dir == \"causal_judgment\"):\n",
    "    #     continue\n",
    "\n",
    "    json_file_path = \"datasets/\" + dir + \"/task.json\"\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        \n",
    "        task = json.load(json_file)\n",
    "\n",
    "        # see README.md --> postprocess method --> \"multiple_choice_grade\" tasks\n",
    "        task['append_choices_to_input'] = True\n",
    "        if task[\"preferred_score\"] == 'multiple_choice_grade':\n",
    "            if \"task_prefix\" not in task.keys():\n",
    "                task[\"task_prefix\"] = \"Please only answer with the choice provided, any extra explanation is forbiddened.\"\n",
    "            else:\n",
    "                task[\"task_prefix\"] += \"Please only answer with the choice provided, any extra explanation is forbiddened.\"\n",
    "        \n",
    "        # see README.md --> postprocess method --> \"exact_str_match\" tasks --> 2\n",
    "        if task[\"name\"] == 'object_counting': \n",
    "            task[\"task_prefix\"] = \"Please answer numbers only.\"\n",
    "        \n",
    "        for emotional_stimulus in EMOTIONAL_STIMULI:\n",
    "\n",
    "\n",
    "            if \"task_prefix\" not in task.keys():\n",
    "                task[\"task_prefix\"] = emotional_stimulus\n",
    "            else:\n",
    "                task[\"task_prefix\"] += emotional_stimulus\n",
    "                \n",
    "            \n",
    "            current_task = json_task.JsonTask(\n",
    "                task_data=task,\n",
    "                shot_list=[0],\n",
    "                max_examples=5 # Should be 100 for final evaluation\n",
    "            )\n",
    "            model = GPTModel(\"gpt-3.5-turbo\")\n",
    "            score_data = current_task.evaluate_model(model)\n",
    "            print(score_data)\n",
    "            print(calculate_normalized_score(score_data[0]))\n",
    "            print(\"-------------------------------------------------\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_prompt_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
